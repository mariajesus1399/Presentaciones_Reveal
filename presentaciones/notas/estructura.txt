Introducción a la probabilidad
La probabilidad es una rama de la matemática con inmensa aplicación práctica en muchas disciplinas: desde el quehacer personal y doméstico hasta grandes decisiones sociales. En nuestra disciplina es, además, fundamental para el análisis de señales y sistemas.
	
Probabilidad conjunta, condicional y teorema de Bayes
Una gran cantidad de "experimentos" y cálculos de probabilidad cotidianos pueden ser descritos por medio de las herramientas de la probabilidad condicional y conjunta, el teorema de Bayes y los eventos independientes, que representan un conocimiento básico y útil de la probabilidad.

Eventos independientes
La independencia estadística es una simplificación útil en los cálculos de probabilidad. Implica que la ocurrencia de un evento no afecta la probabilidad de ocurrencia de otro evento independiente.

Variables aleatorias
Las variables aleatorias facilitan una manipulación numérica más robusta de los fenómenos aleatorios, y permiten extender el análisis a muchos más casos que los vistos hasta ahora. Herramientas como las funciones de densidad y de distribución acumulativa de probabilidad proveen descripciones completas de los modelos probabilísticos.
	
Momentos de las variables aleatorias
El valor esperado y los "momentos" (su generalización) permiten caracterizar numéricamente el comportamiento o las tendencias de una variable aleatoria.
	
Transformaciones de las variables aleatorias
Las transformaciones permiten determinar la función de densidad probabilística de una variable aleatoria Y a partir del conocimiento de otra variable aleatoria X, relacionadas por la función Y = T(X) = g(X). Es común en situaciones donde el resultado de un proceso o la salida de un sistema depende de una entrada aleatoria.

Variables aleatorias múltiples
En muchos experimentos, las observaciones no son una sola cantidad, sino un grupo o familia de cantidades. Por tanto, se construyen vectores de variables aleatorias, llamados vectores aleatorios.

Momentos de las variables aleatorias múltiples
Es posible determinar momentos asociados con dos o más variables aleatorias. La información que proveen, al igual que con las variables aleatorias individuales, son útiles como descriptores generales.

Transformaciones de las variables aleatorias múltiples
Similar al caso de las variables aleatorias marginales, es posible "transformar" dos o más variables aleatorias conjuntas mediante funciones, y el objetivo es encontrar la función de densidad de las nuevas variables aleatorias conjuntas.

Teorema del límite central y otros
El teorema del límite central establece que la función de distribución probabilística de la suma o de las medias muestrales de un número grande de variables aleatorias aproxima a una distribución gaussiana (normal).

Procesos estocásticos
Los procesos aleatorios (o estocásticos) son los terceros "objetos aleatorios" que analizaremos. Incorporan una segunda variable independiente, el tiempo, que los hace útiles en la descripción de fenómenos cambiantes o dinámicos tales como las señales y los sistemas.

Ergodicidad y funciones de correlación de procesos estocásticos
La ergodicidad establece la igualdad entre el promedio estadístico y el promedio temporal de un proceso aleatorio. Es una nueva forma de estacionaridad que simplifica el análisis del proceso aleatorio.

Características espectrales de procesos estocásticos
Cuando los procesos estocásticos describen señales (funciones unidimensionales en el tiempo), es posible analizarlos según sus características espectrales, es decir, relativas a la frecuencia. Esto es útil en aplicaciones de procesamiento de señales: sensores, audio, sistemas de control, comunicaciones, estabilidad de sistemas de potencia, y otras.

Respuesta de sistemas lineales a una señal aleatoria
En la interacción de señales y sistemas donde hay entradas aleatorias, es posible determinar cantidades útiles para el análisis, como la señal misma o la potencia de salida, conociendo las características determinísticas del sistema y características estadísticas de la entrada.

Cadenas de Markov de tiempo continuo
Muchos fenómenos del mundo real pueden ser modelados como una secuencia de transiciones de un estado a otro, donde cada transición tiene una incertidumbre asociada. Las cadenas de Markov proveen un modelo para información secuencial que permite que resultados futuros dependan de otros resultados previos.
	
Vector de estado estable de cadenas de Markov de tiempo continuo
Luego de suficientes transiciones de estados, la probabilidad de ocurrencia de un estado se estabiliza en un valor constante. A cada estado, por tanto, se le asigna una probabilidad de estado estable.

Cadenas de Markov de tiempo discreto
Cuando existe una cantidad definida de estados, es posible modelar las transiciones entre todos estos estados. Luego de suficientes transiciones, y al alcanzar un "régimen permanente", cada estado tiene una probabilidad definida.

{% extends 'plataforma.html' %}

{% load static %}

{% block content %}
    <p>Sesiones sincrónicas por cada una de las 16 semanas del ciclo lectivo.</p>

    <!-- Step -->
<ul class="step step-border-last-0">
    <li class="step-item">
      <div class="step-content-wrapper">
        <span class="step-icon step-icon-soft-primary">1</span>
        <div class="step-content">
          <h4>Introducción a la probabilidad</h4>
          <p class="step-text">La probabilidad es una rama de la matemática con inmensa aplicación práctica en muchas disciplinas: desde el quehacer personal y doméstico hasta grandes decisiones sociales. En nuestra disciplina es, además, fundamental para el análisis de señales y sistemas.</p>
        </div>
      </div>
    </li>

    <li class="step-item">
        <div class="step-content-wrapper">
          <span class="step-icon step-icon-soft-primary">2</span>
          <div class="step-content">
            <h4>Probabilidad conjunta, condicional y teorema de Bayes</h4>
            <p class="step-text">Una gran cantidad de "experimentos" y cálculos de probabilidad cotidianos pueden ser descritos por medio de las herramientas de la probabilidad condicional y conjunta, el teorema de Bayes y los eventos independientes, que representan un conocimiento básico y útil de la probabilidad.</p>
          </div>
        </div>
      </li>

      <li class="step-item">
        <div class="step-content-wrapper">
          <span class="step-icon step-icon-soft-primary">3</span>
          <div class="step-content">
            <h4>Eventos independientes</h4>
            <p class="step-text">La independencia estadística es una simplificación útil en los cálculos de probabilidad. Implica que la ocurrencia de un evento no afecta la probabilidad de ocurrencia de otro evento independiente.</p>
          </div>
        </div>
      </li>

      <li class="step-item">
        <div class="step-content-wrapper">
          <span class="step-icon step-icon-soft-primary">4</span>
          <div class="step-content">
            <h4>Variables aleatorias</h4>
            <p class="step-text">Las variables aleatorias facilitan una manipulación numérica más robusta de los fenómenos aleatorios, y permiten extender el análisis a muchos más casos que los vistos hasta ahora. Herramientas como las funciones de densidad y de distribución acumulativa de probabilidad proveen descripciones completas de los modelos probabilísticos.</p>
          </div>
        </div>
      </li>

      <li class="step-item">
        <div class="step-content-wrapper">
          <span class="step-icon step-icon-soft-primary">5</span>
          <div class="step-content">
            <h4>Momentos de las variables aleatorias</h4>
            <p class="step-text">El valor esperado y los "momentos" (su generalización) permiten caracterizar numéricamente el comportamiento o las tendencias de una variable aleatoria.</p>
          </div>
        </div>
      </li>

      <li class="step-item">
        <div class="step-content-wrapper">
          <span class="step-icon step-icon-soft-primary">6</span>
          <div class="step-content">
            <h4>Transformaciones de las variables aleatorias</h4>
            <p class="step-text">Las transformaciones permiten determinar la función de densidad probabilística de una variable aleatoria Y a partir del conocimiento de otra variable aleatoria X, relacionadas por la función Y = T(X) = g(X). Es común en situaciones donde el resultado de un proceso o la salida de un sistema depende de una entrada aleatoria.</p>
          </div>
        </div>
      </li>

      <li class="step-item">
        <div class="step-content-wrapper">
          <span class="step-icon step-icon-soft-primary">7</span>
          <div class="step-content">
            <h4>Variables aleatorias múltiples</h4>
            <p class="step-text">En muchos experimentos, las observaciones no son una sola cantidad, sino un grupo o familia de cantidades. Por tanto, se construyen vectores de variables aleatorias, llamados vectores aleatorios.</p>
          </div>
        </div>
      </li>

      <li class="step-item">
        <div class="step-content-wrapper">
          <span class="step-icon step-icon-soft-primary">8</span>
          <div class="step-content">
            <h4>Transformaciones de las variables aleatorias múltiples</h4>
            <p class="step-text">Similar al caso de las variables aleatorias marginales, es posible "transformar" dos o más variables aleatorias conjuntas mediante funciones, y el objetivo es encontrar la función de densidad de las nuevas variables aleatorias conjuntas.</p>
          </div>
        </div>
      </li>

      <li class="step-item">
        <div class="step-content-wrapper">
          <span class="step-icon step-icon-soft-primary">9</span>
          <div class="step-content">
            <h4>Teorema del límite central y otros</h4>
            <p class="step-text">El teorema del límite central establece que la función de distribución probabilística de la suma o de las medias muestrales de un número grande de variables aleatorias aproxima a una distribución gaussiana (normal).</p>
          </div>
        </div>
      </li>

      <li class="step-item">
        <div class="step-content-wrapper">
          <span class="step-icon step-icon-soft-primary">10</span>
          <div class="step-content">
            <h4>Procesos estocásticos</h4>
            <p class="step-text">Los procesos aleatorios (o estocásticos) son los terceros "objetos aleatorios" que analizaremos. Incorporan una segunda variable independiente, el tiempo, que los hace útiles en la descripción de fenómenos cambiantes o dinámicos tales como las señales y los sistemas.</p>
          </div>
        </div>
      </li>

      <li class="step-item">
        <div class="step-content-wrapper">
          <span class="step-icon step-icon-soft-primary">11</span>
          <div class="step-content">
            <h4>Ergodicidad y funciones de correlación de procesos estocásticos</h4>
            <p class="step-text">La ergodicidad establece la igualdad entre el promedio estadístico y el promedio temporal de un proceso aleatorio. Es una nueva forma de estacionaridad que simplifica el análisis del proceso aleatorio.</p>
          </div>
        </div>
      </li>

      <li class="step-item">
        <div class="step-content-wrapper">
          <span class="step-icon step-icon-soft-primary">12</span>
          <div class="step-content">
            <h4>Características espectrales de procesos estocásticos</h4>
            <p class="step-text">Cuando los procesos estocásticos describen señales (funciones unidimensionales en el tiempo), es posible analizarlos según sus características espectrales, es decir, relativas a la frecuencia. Esto es útil en aplicaciones de procesamiento de señales: sensores, audio, sistemas de control, comunicaciones, estabilidad de sistemas de potencia, y otras.</p>
          </div>
        </div>
      </li>

      <li class="step-item">
        <div class="step-content-wrapper">
          <span class="step-icon step-icon-soft-primary">13</span>
          <div class="step-content">
            <h4>Respuesta de sistemas lineales a una señal aleatoria</h4>
            <p class="step-text">En la interacción de señales y sistemas donde hay entradas aleatorias, es posible determinar cantidades útiles para el análisis, como la señal misma o la potencia de salida, conociendo las características determinísticas del sistema y características estadísticas de la entrada.</p>
          </div>
        </div>
      </li>

      <li class="step-item">
        <div class="step-content-wrapper">
          <span class="step-icon step-icon-soft-primary">14</span>
          <div class="step-content">
            <h4>Cadenas de Markov de tiempo continuo</h4>
            <p class="step-text">Muchos fenómenos del mundo real pueden ser modelados como una secuencia de transiciones de un estado a otro, donde cada transición tiene una incertidumbre asociada. Las cadenas de Markov proveen un modelo para información secuencial que permite que resultados futuros dependan de otros resultados previos.</p>
          </div>
        </div>
      </li>

      <li class="step-item">
        <div class="step-content-wrapper">
          <span class="step-icon step-icon-soft-primary">15</span>
          <div class="step-content">
            <h4>Vector de estado estable de cadenas de Markov de tiempo continuo</h4>
            <p class="step-text">Luego de suficientes transiciones de estados, la probabilidad de ocurrencia de un estado se estabiliza en un valor constante. A cada estado, por tanto, se le asigna una probabilidad de estado estable.</p>
          </div>
        </div>
      </li>

      <li class="step-item">
        <div class="step-content-wrapper">
          <span class="step-icon step-icon-soft-primary">16</span>
          <div class="step-content">
            <h4>Cadenas de Markov de tiempo discreto</h4>
            <p class="step-text">Cuando existe una cantidad definida de estados, es posible modelar las transiciones entre todos estos estados. Luego de suficientes transiciones, y al alcanzar un "régimen permanente", cada estado tiene una probabilidad definida.</p>
          </div>
        </div>
      </li>

  </ul>
  <!-- End Step -->

{% endblock %}